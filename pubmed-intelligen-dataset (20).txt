PMID- 37774374
OWN - NLM
STAT- MEDLINE
DCOM- 20231229
LR  - 20240108
IS  - 1528-0020 (Electronic)
IS  - 0006-4971 (Linking)
VI  - 142
IP  - 26
DP  - 2023 Dec 28
TI  - Spatial mapping of human hematopoiesis at single-cell resolution reveals 
      aging-associated topographic remodeling.
PG  - 2282-2295
LID - 10.1182/blood.2023021280 [doi]
AB  - The spatial anatomy of hematopoiesis in the bone marrow (BM) has been extensively 
      studied in mice and other preclinical models, but technical challenges have 
      precluded a commensurate exploration in humans. Institutional pathology archives 
      contain thousands of paraffinized BM core biopsy tissue specimens, providing a 
      rich resource for studying the intact human BM topography in a variety of 
      physiologic states. Thus, we developed an end-to-end pipeline involving 
      multiparameter whole tissue staining, in situ imaging at single-cell resolution, 
      and artificial intelligence-based digital whole slide image analysis and then 
      applied it to a cohort of disease-free samples to survey alterations in the 
      hematopoietic topography associated with aging. Our data indicate heterogeneity 
      in marrow adipose tissue (MAT) content within each age group and an inverse 
      correlation between MAT content and proportions of early myeloid and erythroid 
      precursors, irrespective of age. We identify consistent endosteal and 
      perivascular positioning of hematopoietic stem and progenitor cells (HSPCs) with 
      medullary localization of more differentiated elements and, importantly, uncover 
      new evidence of aging-associated changes in cellular and vascular morphologies, 
      microarchitectural alterations suggestive of foci with increased lymphocytes, and 
      diminution of a potentially active megakaryocytic niche. Overall, our findings 
      suggest that there is topographic remodeling of human hematopoiesis associated 
      with aging. More generally, we demonstrate the potential to deeply unravel the 
      spatial biology of normal and pathologic human BM states using intact archival 
      tissue specimens.
CI  - © 2023 by The American Society of Hematology.
FAU - Sarachakov, Aleksandr
AU  - Sarachakov A
AD  - BostonGene Corporation, Waltham, MA.
FAU - Varlamova, Arina
AU  - Varlamova A
AUID- ORCID: 0000-0001-6793-608X
AD  - BostonGene Corporation, Waltham, MA.
FAU - Svekolkin, Viktor
AU  - Svekolkin V
AUID- ORCID: 0000-0001-5763-7246
AD  - BostonGene Corporation, Waltham, MA.
FAU - Polyakova, Margarita
AU  - Polyakova M
AUID- ORCID: 0000-0003-0245-4834
AD  - BostonGene Corporation, Waltham, MA.
FAU - Valencia, Itzel
AU  - Valencia I
AUID- ORCID: 0000-0002-7450-9307
AD  - Multiparametric In Situ Imaging Laboratory, Department of Pathology and 
      Laboratory Medicine, Weill Cornell Medicine, New York, NY.
FAU - Unkenholz, Caitlin
AU  - Unkenholz C
AUID- ORCID: 0009-0005-8972-7883
AD  - Multiparametric In Situ Imaging Laboratory, Department of Pathology and 
      Laboratory Medicine, Weill Cornell Medicine, New York, NY.
FAU - Pannellini, Tania
AU  - Pannellini T
AD  - Multiparametric In Situ Imaging Laboratory, Department of Pathology and 
      Laboratory Medicine, Weill Cornell Medicine, New York, NY.
FAU - Galkin, Ilia
AU  - Galkin I
AD  - BostonGene Corporation, Waltham, MA.
FAU - Ovcharov, Pavel
AU  - Ovcharov P
AD  - BostonGene Corporation, Waltham, MA.
FAU - Tabakov, Dmitrii
AU  - Tabakov D
AUID- ORCID: 0000-0002-1509-2206
AD  - BostonGene Corporation, Waltham, MA.
FAU - Postovalova, Ekaterina
AU  - Postovalova E
AUID- ORCID: 0000-0002-3413-3122
AD  - BostonGene Corporation, Waltham, MA.
FAU - Shin, Nara
AU  - Shin N
AUID- ORCID: 0000-0002-9910-4971
AD  - BostonGene Corporation, Waltham, MA.
FAU - Sethi, Isha
AU  - Sethi I
AD  - BostonGene Corporation, Waltham, MA.
FAU - Bagaev, Alexander
AU  - Bagaev A
AUID- ORCID: 0000-0002-8680-854X
AD  - BostonGene Corporation, Waltham, MA.
FAU - Itkin, Tomer
AU  - Itkin T
AD  - Division of Regenerative Medicine, Department of Medicine, Hartman Institute for 
      Therapeutic Organ Regeneration, Ansary Stem Cell Institute, Weill Cornell 
      Medicine, New York, NY.
FAU - Crane, Genevieve
AU  - Crane G
AD  - Department of Laboratory Medicine, Cleveland Clinic, Robert J. Tomsich Pathology 
      and Laboratory Medicine Institute, Cleveland, OH.
FAU - Kluk, Michael
AU  - Kluk M
AD  - Division of Hematopathology, Department of Pathology and Laboratory Medicine, 
      Weill Cornell Medicine/NewYork-Presbyterian Hospital, New York, NY.
FAU - Geyer, Julia
AU  - Geyer J
AUID- ORCID: 0000-0002-4424-6139
AD  - Division of Hematopathology, Department of Pathology and Laboratory Medicine, 
      Weill Cornell Medicine/NewYork-Presbyterian Hospital, New York, NY.
FAU - Inghirami, Giorgio
AU  - Inghirami G
AUID- ORCID: 0000-0001-5566-0864
AD  - Division of Hematopathology, Department of Pathology and Laboratory Medicine, 
      Weill Cornell Medicine/NewYork-Presbyterian Hospital, New York, NY.
FAU - Patel, Sanjay
AU  - Patel S
AUID- ORCID: 0000-0002-7813-4573
AD  - Multiparametric In Situ Imaging Laboratory, Department of Pathology and 
      Laboratory Medicine, Weill Cornell Medicine, New York, NY.
AD  - Division of Hematopathology, Department of Pathology and Laboratory Medicine, 
      Weill Cornell Medicine/NewYork-Presbyterian Hospital, New York, NY.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Blood
JT  - Blood
JID - 7603509
SB  - IM
CIN - Blood. 2023 Dec 28;142(26):2225-2226. PMID: 38153772
MH  - Humans
MH  - Mice
MH  - Animals
MH  - *Artificial Intelligence
MH  - *Hematopoietic Stem Cells/pathology
MH  - Bone Marrow/pathology
MH  - Hematopoiesis/physiology
MH  - Aging
EDAT- 2023/09/29 18:41
MHDA- 2023/12/29 06:43
CRDT- 2023/09/29 16:33
PHST- 2023/09/27 00:00 [accepted]
PHST- 2023/05/23 00:00 [received]
PHST- 2023/12/29 06:43 [medline]
PHST- 2023/09/29 18:41 [pubmed]
PHST- 2023/09/29 16:33 [entrez]
AID - 498177 [pii]
AID - 10.1182/blood.2023021280 [doi]
PST - ppublish
SO  - Blood. 2023 Dec 28;142(26):2282-2295. doi: 10.1182/blood.2023021280.

PMID- 37774313
OWN - NLM
STAT- MEDLINE
DCOM- 20231115
LR  - 20231122
IS  - 2473-4276 (Electronic)
IS  - 2473-4276 (Linking)
VI  - 7
DP  - 2023 Sep
TI  - Efficient Augmented Intelligence Framework for Bladder Lesion Detection.
PG  - e2300031
LID - 10.1200/CCI.23.00031 [doi]
LID - e2300031
AB  - PURPOSE: Development of intelligence systems for bladder lesion detection is cost 
      intensive. An efficient strategy to develop such intelligence solutions is 
      needed. MATERIALS AND METHODS: We used four deep learning models (ConvNeXt, 
      PlexusNet, MobileNet, and SwinTransformer) covering a variety of model complexity 
      and efficacy. We trained these models on a previously published educational 
      cystoscopy atlas (n = 312 images) to estimate the ratio between normal and cancer 
      scores and externally validated on cystoscopy videos from 68 cases, with region 
      of interest (ROI) pathologically confirmed to be benign and cancerous bladder 
      lesions (ie, ROI). The performance measurement included specificity and 
      sensitivity at frame level, frame sequence (block) level, and ROI level for each 
      case. RESULTS: Specificity was comparable between four models at frame (range, 
      30.0%-44.8%) and block levels (56%-67%). Although sensitivity at the frame level 
      (range, 81.4%-88.1%) differed between the models, sensitivity at the block level 
      (100%) and ROI level (100%) was comparable between these models. MobileNet and 
      PlexusNet were computationally more efficient for real-time ROI detection than 
      ConvNeXt and SwinTransformer. CONCLUSION: Educational cystoscopy atlas and 
      efficient models facilitate the development of real-time intelligence system for 
      bladder lesion detection.
FAU - Eminaga, Okyaz
AU  - Eminaga O
AUID- ORCID: 0000-0003-0861-3138
AD  - AI Vobis, Palo Alto, CA.
AD  - Center for Artificial Intelligence in Medicine and Imaging, Stanford University 
      School of Medicine, Stanford, CA.
FAU - Lee, Timothy Jiyong
AU  - Lee TJ
AD  - Department of Urology, Stanford University School of Medicine, Stanford, CA.
AD  - Veterans Affairs Palo Alto Health Care System, Palo Alto, CA.
FAU - Laurie, Mark
AU  - Laurie M
AUID- ORCID: 0000-0001-6042-2094
AD  - Department of Urology, Stanford University School of Medicine, Stanford, CA.
AD  - Department of Radiation Oncology, Stanford University School of Medicine, 
      Stanford, CA.
FAU - Ge, T Jessie
AU  - Ge TJ
AUID- ORCID: 0000-0002-3618-3051
AD  - Department of Urology, Stanford University School of Medicine, Stanford, CA.
FAU - La, Vinh
AU  - La V
AUID- ORCID: 0000-0002-6980-300X
AD  - Department of Urology, Stanford University School of Medicine, Stanford, CA.
FAU - Long, Jin
AU  - Long J
AD  - Center for Artificial Intelligence in Medicine and Imaging, Stanford University 
      School of Medicine, Stanford, CA.
FAU - Semjonow, Axel
AU  - Semjonow A
AD  - Department of Urology, Muenster University Hospital, Muenster, Germany.
FAU - Bogemann, Martin
AU  - Bogemann M
AUID- ORCID: 0000-0002-2569-4446
AD  - Department of Urology, Muenster University Hospital, Muenster, Germany.
FAU - Lau, Hubert
AU  - Lau H
AUID- ORCID: 0000-0003-2715-2779
AD  - Veterans Affairs Palo Alto Health Care System, Palo Alto, CA.
FAU - Shkolyar, Eugene
AU  - Shkolyar E
AD  - Department of Urology, Stanford University School of Medicine, Stanford, CA.
FAU - Xing, Lei
AU  - Xing L
AD  - Center for Artificial Intelligence in Medicine and Imaging, Stanford University 
      School of Medicine, Stanford, CA.
AD  - Department of Radiation Oncology, Stanford University School of Medicine, 
      Stanford, CA.
FAU - Liao, Joseph C
AU  - Liao JC
AUID- ORCID: 0000-0003-2448-5463
AD  - Center for Artificial Intelligence in Medicine and Imaging, Stanford University 
      School of Medicine, Stanford, CA.
AD  - Department of Urology, Stanford University School of Medicine, Stanford, CA.
AD  - Veterans Affairs Palo Alto Health Care System, Palo Alto, CA.
LA  - eng
GR  - I01 BX005598/BX/BLRD VA/United States
GR  - R01 CA260426/CA/NCI NIH HHS/United States
PT  - Journal Article
PL  - United States
TA  - JCO Clin Cancer Inform
JT  - JCO clinical cancer informatics
JID - 101708809
SB  - IM
MH  - Humans
MH  - *Urinary Bladder Neoplasms/diagnosis/pathology
MH  - Urinary Bladder/pathology
MH  - Sensitivity and Specificity
MH  - Cystoscopy
PMC - PMC10569784
COIS- The following represents disclosure information provided by authors of this 
      manuscript. All relationships are considered compensated unless otherwise noted. 
      Relationships are self-held unless noted. I = Immediate Family Member, Inst = My 
      Institution. Relationships may not relate to the subject matter of this 
      manuscript. For more information about ASCO's conflict of interest policy, please 
      refer to www.asco.org/rwc or ascopubs.org/cci/author-center. Open Payments is a 
      public database containing information reported by companies about payments made 
      to US-licensed physicians (Open Payments). Mark Laurie Employment: 
      Genentech/Roche Stock and Other Ownership Interests: Roche T. Jessie Ge 
      Employment: Stanford Health Care Patents, Royalties, Other Intellectual Property: 
      Patent for MAGSToNE—medical device for kidney stone removal Axel Semjonow Stock 
      and Other Ownership Interests: Philips Healthcare Consulting or Advisory Role: 
      Spinchip Research Funding: Philips Healthcare Patents, Royalties, Other 
      Intellectual Property: Patent: Characterization of Primary Tumors Martin Bogemann 
      Employment: Janssen Honoraria: Janssen-Cilag, Astellas Pharma, Bayer/Vital, 
      Sanofi/Aventis, MSD, Bristol Myers Squibb, Pfizer, Novartis, Ipsen, EUSA Pharma, 
      Merck, Eisai, Amgen, AstraZeneca, Roche, Advanced Accelerator Applications 
      Consulting or Advisory Role: Bayer, Janssen-Cilag, Astellas Pharma, AstraZeneca, 
      MSD, Bristol Myers Squibb, Ipsen, Roche, Novartis, Merck, Sanofi, Eisai Research 
      Funding: Janssen-Cilag, Ipsen (Inst) Travel, Accommodations, Expenses: 
      Janssen-Cilag, Bayer, Amgen, BMS GmbH & Co. KG Eugene Shkolyar Consulting or 
      Advisory Role: Johnson & Johnson/MedTech Patents, Royalties, Other Intellectual 
      Property: Patent related to work on the development of artificial intelligence 
      for bladder cancer detection on cystoscopy Lei Xing Employment: Stanford 
      University Cancer Institute Consulting or Advisory Role: Varian Medical Systems 
      Research Funding: Varian Medical Systems No other potential conflicts of interest 
      were reported.
EDAT- 2023/09/29 18:42
MHDA- 2023/11/15 06:42
PMCR- 2024/09/29
CRDT- 2023/09/29 16:03
PHST- 2024/09/29 00:00 [pmc-release]
PHST- 2023/11/15 06:42 [medline]
PHST- 2023/09/29 18:42 [pubmed]
PHST- 2023/09/29 16:03 [entrez]
AID - CCI.23.00031 [pii]
AID - 10.1200/CCI.23.00031 [doi]
PST - ppublish
SO  - JCO Clin Cancer Inform. 2023 Sep;7:e2300031. doi: 10.1200/CCI.23.00031.

PMID- 37774040
OWN - NLM
STAT- MEDLINE
DCOM- 20240104
LR  - 20240104
IS  - 1469-0705 (Electronic)
IS  - 0960-7692 (Linking)
VI  - 63
IP  - 1
DP  - 2024 Jan
TI  - Deep-learning model for prenatal congenital heart disease screening generalizes 
      to community setting and outperforms clinical detection.
PG  - 44-52
LID - 10.1002/uog.27503 [doi]
AB  - OBJECTIVES: Despite nearly universal prenatal ultrasound screening programs, 
      congenital heart defects (CHD) are still missed, which may result in severe 
      morbidity or even death. Deep machine learning (DL) can automate image 
      recognition from ultrasound. The main aim of this study was to assess the 
      performance of a previously developed DL model, trained on images from a tertiary 
      center, using fetal ultrasound images obtained during the second-trimester 
      standard anomaly scan in a low-risk population. A secondary aim was to compare 
      initial screening diagnosis, which made use of live imaging at the point-of-care, 
      with diagnosis by clinicians evaluating only stored images. METHODS: All 
      pregnancies with isolated severe CHD in the Northwestern region of The 
      Netherlands between 2015 and 2016 with available stored images were evaluated, as 
      well as a sample of normal fetuses' examinations from the same region and time 
      period. We compared the accuracy of the initial clinical diagnosis (made in real 
      time with access to live imaging) with that of the model (which had only stored 
      imaging available) and with the performance of three blinded human experts who 
      had access only to the stored images (like the model). We analyzed performance 
      according to ultrasound study characteristics, such as duration and quality 
      (scored independently by investigators), number of stored images and availability 
      of screening views. RESULTS: A total of 42 normal fetuses and 66 cases of 
      isolated CHD at birth were analyzed. Of the abnormal cases, 31 were missed and 35 
      were detected at the time of the clinical anatomy scan (sensitivity, 53%). Model 
      sensitivity and specificity were 91% and 78%, respectively. Blinded human experts 
      (n = 3) achieved mean ± SD sensitivity and specificity of 55 ± 10% (range, 
      47-67%) and 71 ± 13% (range, 57-83%), respectively. There was a statistically 
      significant difference in model correctness according to expert-graded image 
      quality (P = 0.03). The abnormal cases included 19 lesions that the model had not 
      encountered during its training; the model's performance in these cases (16/19 
      correct) was not statistically significantly different from that for previously 
      encountered lesions (P = 0.41). CONCLUSIONS: A previously trained DL algorithm 
      had higher sensitivity than initial clinical assessment in detecting CHD in a 
      cohort in which over 50% of CHD cases were initially missed clinically. Notably, 
      the DL algorithm performed well on community-acquired images in a low-risk 
      population, including lesions to which it had not been exposed previously. 
      Furthermore, when both the model and blinded human experts had access to only 
      stored images and not the full range of images available to a clinician during a 
      live scan, the model outperformed the human experts. Together, these findings 
      support the proposition that use of DL models can improve prenatal detection of 
      CHD. © 2023 International Society of Ultrasound in Obstetrics and Gynecology.
CI  - © 2023 International Society of Ultrasound in Obstetrics and Gynecology.
FAU - Athalye, C
AU  - Athalye C
AD  - Division of Cardiology, Department of Medicine, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - van Nisselrooij, A
AU  - van Nisselrooij A
AD  - Department of Obstetrics, Division of Fetal Medicine, Leiden University Medical 
      Center, Leiden, The Netherlands.
FAU - Rizvi, S
AU  - Rizvi S
AD  - Division of Cardiology, Department of Medicine, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - Haak, M C
AU  - Haak MC
AUID- ORCID: 0000-0002-0443-1997
AD  - Department of Obstetrics, Division of Fetal Medicine, Leiden University Medical 
      Center, Leiden, The Netherlands.
FAU - Moon-Grady, A J
AU  - Moon-Grady AJ
AD  - Department of Pediatrics, Division of Cardiology, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - Arnaout, R
AU  - Arnaout R
AUID- ORCID: 0000-0002-7134-0040
AD  - Division of Cardiology, Department of Medicine, University of California, San 
      Francisco, San Francisco, CA, USA.
AD  - Department of Pediatrics, Division of Cardiology, University of California, San 
      Francisco, San Francisco, CA, USA.
AD  - Bakar Computational Health Sciences Institute; Department of Radiology; UCSF 
      Berkeley Joint Program in Computational Precision Health; Center for Intelligent 
      Imaging; Biological and Medical Informatics, University of California, San 
      Francisco, San Francisco, CA, USA.
LA  - eng
GR  - NH/NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - Ultrasound Obstet Gynecol
JT  - Ultrasound in obstetrics & gynecology : the official journal of the International 
      Society of Ultrasound in Obstetrics and Gynecology
JID - 9108340
SB  - IM
MH  - Female
MH  - Infant, Newborn
MH  - Pregnancy
MH  - Humans
MH  - *Deep Learning
MH  - *Heart Defects, Congenital/diagnostic imaging/epidemiology
MH  - Prenatal Diagnosis/methods
MH  - Ultrasonography, Prenatal/methods
MH  - Sensitivity and Specificity
OTO - NOTNLM
OT  - artificial intelligence
OT  - congenital heart disease
OT  - fetal screening
OT  - machine learning
OT  - ultrasound
EDAT- 2023/09/29 18:42
MHDA- 2024/01/04 11:44
CRDT- 2023/09/29 15:53
PHST- 2023/09/18 00:00 [revised]
PHST- 2023/03/11 00:00 [received]
PHST- 2023/09/19 00:00 [accepted]
PHST- 2024/01/04 11:44 [medline]
PHST- 2023/09/29 18:42 [pubmed]
PHST- 2023/09/29 15:53 [entrez]
AID - 10.1002/uog.27503 [doi]
PST - ppublish
SO  - Ultrasound Obstet Gynecol. 2024 Jan;63(1):44-52. doi: 10.1002/uog.27503.

PMID- 37773591
OWN - NLM
STAT- Publisher
LR  - 20230929
IS  - 1550-5073 (Electronic)
IS  - 0893-2190 (Linking)
DP  - 2023 Sep 28
TI  - Evaluation of Comfort Behavior Levels of Newborn by Artificial Intelligence 
      Techniques.
LID - 10.1097/JPN.0000000000000768 [doi]
AB  - BACKGROUND: One of the scales most frequently used in the evaluation of newborn 
      comfort levels is the Neonatal Comfort Behavior Scale (NCBS). It is important 
      therefore that an increased use of the NCBS is encouraged through a more 
      practical method of assessment. OBJECTIVE: This study was carried out for the 
      purpose of designing a means of assessing neonatal comfort levels by employing 
      the techniques of artificial intelligence (AI). METHODS: The AI-based study was 
      conducted with 362 newborns under treatment in the neonatal intensive care unit 
      of a hospital. A data collection form, the NCBS, and a camera system were used as 
      data collection tools. The data were analyzed with the SPSS Statistics 21.0 
      program. Descriptive statistics and Cohen κ test were employed in the analysis. 
      RESULTS: The 2 researchers named in the study first labeled the audiovisual 
      recordings of the 362 newborns in the study. These labeled audiovisual recordings 
      were used in training (80%) as well as testing (20%) the AI model. The AI model 
      displayed a rate of success of 99.82%. CONCLUSION: It was ultimately seen that 
      the AI model that had been developed was a successful tool that could be used to 
      determine the comfort behavior levels of newborns in the neonatal intensive care 
      unit.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Yigit, Deniz
AU  - Yigit D
AUID- ORCID: 0000-0001-5627-7963
AD  - Department of Child Health and Diseases Nursing, Faculty of Health Sciences, 
      Kütahya University of Health Sciences, Kutahya, Turkey (Dr Yigit); and Department 
      of Child Health and Diseases Nursing, Faculty of Health Sciences, Eskisehir 
      Osmangazi University, Eskisehir, Turkey (Dr Acikgoz).
FAU - Acikgoz, Ayfer
AU  - Acikgoz A
LA  - eng
PT  - Journal Article
DEP - 20230928
PL  - United States
TA  - J Perinat Neonatal Nurs
JT  - The Journal of perinatal & neonatal nursing
JID - 8801387
EDAT- 2023/09/29 18:42
MHDA- 2023/09/29 18:42
CRDT- 2023/09/29 15:36
PHST- 2023/09/29 18:42 [medline]
PHST- 2023/09/29 18:42 [pubmed]
PHST- 2023/09/29 15:36 [entrez]
AID - 00005237-990000000-00015 [pii]
AID - 10.1097/JPN.0000000000000768 [doi]
PST - aheadofprint
SO  - J Perinat Neonatal Nurs. 2023 Sep 28. doi: 10.1097/JPN.0000000000000768.

PMID- 37773477
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231122
IS  - 2193-8245 (Print)
IS  - 2193-6528 (Electronic)
VI  - 12
IP  - 6
DP  - 2023 Dec
TI  - Biomarkers for the Progression of Intermediate Age-Related Macular Degeneration.
PG  - 2917-2941
LID - 10.1007/s40123-023-00807-9 [doi]
AB  - Age-related macular degeneration (AMD) is a leading cause of severe vision loss 
      worldwide, with a global prevalence that is predicted to substantially increase. 
      Identifying early biomarkers indicative of progression risk will improve our 
      ability to assess which patients are at greatest risk of progressing from 
      intermediate AMD (iAMD) to vision-threatening late-stage AMD. This is key to 
      ensuring individualized management and timely intervention before substantial 
      structural damage. Some structural biomarkers suggestive of AMD progression risk 
      are well established, such as changes seen on color fundus photography and more 
      recently optical coherence tomography (drusen volume, pigmentary abnormalities). 
      Emerging biomarkers identified through multimodal imaging, including reticular 
      pseudodrusen, hyperreflective foci, and drusen sub-phenotypes, are being 
      intensively explored as risk factors for progression towards late-stage disease. 
      Other structural biomarkers merit further research, such as ellipsoid zone 
      reflectivity and choriocapillaris flow features. The measures of visual function 
      that best detect change in iAMD and correlate with risk of progression remain 
      under intense investigation, with tests such as dark adaptometry and 
      cone-specific contrast tests being explored. Evidence on blood and plasma markers 
      is preliminary, but there are indications that changes in levels of C-reactive 
      protein and high-density lipoprotein cholesterol may be used to stratify patients 
      and predict risk. With further research, some of these biomarkers may be used to 
      monitor progression. Emerging artificial intelligence methods may help evaluate 
      and validate these biomarkers; however, until we have large and well-curated 
      longitudinal data sets, using artificial intelligence effectively to inform 
      clinical trial design and detect outcomes will remain challenging. This is an 
      exciting area of intense research, and further work is needed to establish the 
      most promising biomarkers for disease progression and their use in clinical care 
      and future trials. Ultimately, a multimodal approach may yield the most accurate 
      means of monitoring and predicting future progression towards vision-threatening, 
      late-stage AMD.
CI  - © 2023. The Author(s).
FAU - Lad, Eleonora M
AU  - Lad EM
AUID- ORCID: 0000-0001-8435-521X
AD  - Department of Ophthalmology, Duke University Medical Center, Durham, NC, USA. 
      nora.lad@duke.edu.
FAU - Finger, Robert P
AU  - Finger RP
AD  - Department of Ophthalmology, Medical Faculty Mannheim, Heidelberg University, 
      Mannheim, Germany.
FAU - Guymer, Robyn
AU  - Guymer R
AD  - Centre for Eye Research Australia, Royal Victorian Eye and Ear Hospital, 
      University of Melbourne, Melbourne, Australia.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230929
PL  - England
TA  - Ophthalmol Ther
JT  - Ophthalmology and therapy
JID - 101634502
PMC - PMC10640447
OAB - Age-related macular degeneration, or AMD, is an eye disease that causes vision 
      loss. Worldwide, the number of people with AMD is increasing. It is difficult for 
      doctors to know who, among those with AMD, will get worse and lose some of their 
      sight, and who will not. Researchers are trying to find early signs that predict 
      whether AMD will get worse and ways to track AMD progression over time. These 
      signs are known as “biomarkers.” They can be structural (seen in the structures 
      inside the eye), functional (a change in how well someone sees), genetic, or 
      proteins found in the blood. Being able to identify people with AMD that are most 
      at risk of losing their vision will help to make sure they get more frequent 
      review so that interventions can be started quickly before vision is lost 
      permanently. Some structural and functional biomarkers are already well known, 
      while others may be useful and are being intensively researched. Changes in the 
      blood markers need much more research to be useful. Researchers are also looking 
      at how to combine data from different biomarkers. This may be a better way to 
      follow worsening of AMD over time compared to using a single biomarker. In the 
      future, we may also be able to use artificial intelligence to help combine all 
      biomarker data. This is an exciting area of research that will be important to 
      help improve the vision outcomes for people with AMD.
OABL- eng
OTO - NOTNLM
OT  - Age-related macular degeneration
OT  - Biomarkers
OT  - Geographic atrophy
OT  - Neovascular AMD
OT  - iAMD
COIS- Eleonora Lad declares consultancy/scientific advisory boards of Roche, Novartis, 
      Apellis, Allegro, Alexion, Annexon, Aspen Neuroscience, Broadwing Bio, Gemini 
      Therapeutics, Retrotope, Galimedix, IVERIC Bio, NGM Biopharmaceuticals, Janssen, 
      Thea Laboratoires, Nanoscope Therapeutics, Perceive Bio, and Osanni Bio, as well 
      as research funding through Duke University from Roche, Novartis, Apellis, 
      Neurotech, Alexion, IVERIC Bio, LumiThera, Gemini Therapeutics, Boehringer 
      Ingelheim, NGM Biopharmaceuticals, and Janssen. Robert Finger declares research 
      funding from Biogen; consultancy/advisory board for Apellis, Alimera, Bayer, 
      Boehringer Ingelheim, Biogen, Novartis, Roche/Genentech, ODOS and ProGenerika. 
      Robyn Guymer declares consultancy and/or advisory boards of Roche, Genentech, 
      Apellis, Bayer, Novartis, Belite Bio, Character Bioscience, Boehringer Ingelheim 
      Pharmaceuticals, Ocular Therapeutix.
EDAT- 2023/09/29 18:42
MHDA- 2023/09/29 18:43
CRDT- 2023/09/29 15:14
PHST- 2023/07/14 00:00 [received]
PHST- 2023/08/30 00:00 [accepted]
PHST- 2023/09/29 18:43 [medline]
PHST- 2023/09/29 18:42 [pubmed]
PHST- 2023/09/29 15:14 [entrez]
AID - 10.1007/s40123-023-00807-9 [pii]
AID - 807 [pii]
AID - 10.1007/s40123-023-00807-9 [doi]
PST - ppublish
SO  - Ophthalmol Ther. 2023 Dec;12(6):2917-2941. doi: 10.1007/s40123-023-00807-9. Epub 
      2023 Sep 29.

PMID- 37773456
OWN - NLM
STAT- Publisher
LR  - 20230929
IS  - 1615-6714 (Electronic)
IS  - 1434-5293 (Linking)
DP  - 2023 Sep 29
TI  - Facial recognition by cloud-based APIs following surgically assisted rapid 
      maxillary expansion.
LID - 10.1007/s00056-023-00494-y [doi]
AB  - INTRODUCTION: This study aimed to investigate whether the facial soft tissue 
      changes of individuals who had undergone surgically assisted rapid maxillary 
      expansion (SARME) would be detected by three different well-known facial 
      biometric recognition applications. METHODS: To calculate similarity scores, the 
      pre- and postsurgical photographs of 22 patients who had undergone SARME 
      treatment were examined using three prominent cloud computing-based facial 
      recognition application programming interfaces (APIs): AWS Rekognition (Amazon 
      Web Services, Seattle, WA, USA), Microsoft Azure Cognitive (Microsoft, Redmond, 
      WA, USA), and Face++ (Megvii, Beijing, China). The pre- and post-SARME 
      photographs of the patients (relaxed, smiling, profile, and semiprofile) were 
      used to calculate similarity scores using the APIs. Friedman's two-way analysis 
      of variance and the Wilcoxon signed-rank test were used to compare the similarity 
      scores obtained from the photographs of the different aspects of the face before 
      and after surgery using the different programs. The relationship between 
      measurements on lateral and posteroanterior cephalograms and the similarity 
      scores was evaluated using the Spearman rank correlation. RESULTS: The similarity 
      scores were found to be lower with the Face++ program. When looking at the photo 
      types, it was observed that the similarity scores were higher in the smiling 
      photos. A statistically significant difference in the similarity scores 
      (P < 0.05) was found between the relaxed and smiling photographs using the 
      different programs. The correlation between the cephalometric and posteroanterior 
      measurements and the similarity scores was not significant (P > 0.05). 
      CONCLUSION: SARME treatment caused a significant change in the similarity scores 
      calculated with the help of three different facial recognition programs. The 
      highest similarity scores were found in the smiling photographs, whereas the 
      lowest scores were found in the profile photographs.
CI  - © 2023. The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, 
      ein Teil von Springer Nature.
FAU - Buyukcavus, Muhammed Hilmi
AU  - Buyukcavus MH
AUID- ORCID: 0000-0003-2184-1549
AD  - Faculty of Dentistry, Department of Orthodontics, Antalya Bilim University, 
      Antalya, Turkey. mhbuyukcvs@gmail.com.
FAU - Aydogan Akgun, Filiz
AU  - Aydogan Akgun F
AUID- ORCID: 0000-0003-1977-3778
AD  - Faculty of Dentistry, Department of Orthodontics, Burdur Mehmet Akif Ersoy 
      University, Burdur, Turkey.
FAU - Solak, Serdar
AU  - Solak S
AUID- ORCID: 0000-0003-1081-1598
AD  - Faculty of Technology, Department of Information Systems Engineering, Kocaeli 
      University, Kocaeli, Turkey.
FAU - Ucar, Mustafa Hikmet Bilgehan
AU  - Ucar MHB
AUID- ORCID: 0000-0002-9023-0023
AD  - Faculty of Technology, Department of Information Systems Engineering, Kocaeli 
      University, Kocaeli, Turkey.
FAU - Fındık, Yavuz
AU  - Fındık Y
AUID- ORCID: 0000-0003-3483-3177
AD  - Faculty of Dentistry, Department of Department of Oral and Maxillofacial Surgery, 
      Süleyman Demirel University, Isparta, Turkey.
FAU - Baykul, Timucin
AU  - Baykul T
AUID- ORCID: 0000-0003-1621-1112
AD  - Faculty of Dentistry, Department of Department of Oral and Maxillofacial Surgery, 
      Süleyman Demirel University, Isparta, Turkey.
LA  - eng
PT  - Journal Article
TT  - Gesichtserkennung über Cloud-basierte APIs nach chirurgisch unterstützter 
      schneller Gaumennahterweiterung.
DEP - 20230929
PL  - Germany
TA  - J Orofac Orthop
JT  - Journal of orofacial orthopedics = Fortschritte der Kieferorthopadie : 
      Organ/official journal Deutsche Gesellschaft fur Kieferorthopadie
JID - 9713484
SB  - IM
OTO - NOTNLM
OT  - Amazon Web Services
OT  - Application programming interfaces
OT  - Artificial intelligence
OT  - Azure
OT  - Face++
EDAT- 2023/09/29 18:41
MHDA- 2023/09/29 18:41
CRDT- 2023/09/29 15:08
PHST- 2022/04/13 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/09/29 18:41 [medline]
PHST- 2023/09/29 18:41 [pubmed]
PHST- 2023/09/29 15:08 [entrez]
AID - 10.1007/s00056-023-00494-y [pii]
AID - 10.1007/s00056-023-00494-y [doi]
PST - aheadofprint
SO  - J Orofac Orthop. 2023 Sep 29. doi: 10.1007/s00056-023-00494-y.

PMID- 37773288
OWN - NLM
STAT- Publisher
LR  - 20230929
IS  - 1435-702X (Electronic)
IS  - 0721-832X (Linking)
DP  - 2023 Sep 29
TI  - Use of extreme gradient boosting, light gradient boosting machine, and deep 
      neural networks to evaluate the activity stage of extraocular muscles in 
      thyroid-associated ophthalmopathy.
LID - 10.1007/s00417-023-06256-1 [doi]
AB  - PURPOSE: To develop a machine learning model to evaluate the activity stage of 
      extraocular muscles in thyroid-associated ophthalmopathy (TAO). METHODS: This 
      study retrospectively analysed data from patients with TAO who underwent 
      contrast-enhanced magnetic resonance imaging (MRI) from 2015 to 2022. Three 
      independent machine learning models, namely, extreme gradient boosting (XGBoost), 
      light gradient boosting machine (LightGBM), and deep neural networks (DNNs), were 
      constructed using common clinical features. The performance of these models was 
      compared using evaluation metrics such as the area under the receiver operating 
      curve (AUC), accuracy, precision, recall, and F1 score. The importance of 
      features was explained using Shapley additive explanations (SHAP). RESULTS: A 
      total of 2561 eyes of 1479 TAO patients were included in this study. The original 
      dataset was randomly divided into a training set (80%, n = 2048) and a test set 
      (20%, n = 513). In the performance evaluation of the test set, the LightGBM model 
      had the best diagnostic performance (AUC 0.9260). According to the SHAP results, 
      features such as conjunctival congestion, swollen caruncles, oedema of the upper 
      eyelid, course of TAO, and intraocular pressure had the most significant impact 
      on the LightGBM model. CONCLUSION: This study used contrast-enhanced MRI as an 
      objective evaluation criterion and constructed a LightGBM model based on readily 
      accessible clinical data. The model had good classification performance, making 
      it a promising artificial intelligence (AI)-assisted tool to help community 
      hospitals evaluate the inflammatory activity of extraocular muscles in TAO 
      patients in a timely manner.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Li, Yunfei
AU  - Li Y
AD  - Department of Ophthalmology, West China Hospital of Sichuan University, No. 37 
      Guoxue Xiang, Wuhou District, Chengdu, 610041, Sichuan Province, China.
FAU - Ma, Jingyu
AU  - Ma J
AD  - School of Mathematics and Statistics, Lanzhou University, 222 South Tianshui Rd, 
      Lanzhou, 730000, Gansu Province, China.
FAU - Xiao, Jun
AU  - Xiao J
AD  - School of Materials and Energy, Lanzhou University, 222 South Tianshui Rd, 
      Lanzhou, 730000, Gansu Province, China.
FAU - Wang, Yujiao
AU  - Wang Y
AD  - Department of Ophthalmology, West China Hospital of Sichuan University, No. 37 
      Guoxue Xiang, Wuhou District, Chengdu, 610041, Sichuan Province, China.
FAU - He, Weimin
AU  - He W
AUID- ORCID: 0000-0002-0103-3678
AD  - Department of Ophthalmology, West China Hospital of Sichuan University, No. 37 
      Guoxue Xiang, Wuhou District, Chengdu, 610041, Sichuan Province, China. 
      hewm888@hotmail.com.
LA  - eng
GR  - 22KJPX0238/science and technology program of Sichuan province/
GR  - C2023122969/College Students' innovative entrepreneurial training plan program/
PT  - Journal Article
DEP - 20230929
PL  - Germany
TA  - Graefes Arch Clin Exp Ophthalmol
JT  - Graefe's archive for clinical and experimental ophthalmology = Albrecht von 
      Graefes Archiv fur klinische und experimentelle Ophthalmologie
JID - 8205248
SB  - IM
OTO - NOTNLM
OT  - Deep neural networks
OT  - Disease activity
OT  - Extreme gradient boosting
OT  - Light gradient boosting machine
OT  - Machine learning
OT  - Thyroid-associated ophthalmopathy
EDAT- 2023/09/29 18:42
MHDA- 2023/09/29 18:42
CRDT- 2023/09/29 14:28
PHST- 2023/06/01 00:00 [received]
PHST- 2023/09/21 00:00 [accepted]
PHST- 2023/09/14 00:00 [revised]
PHST- 2023/09/29 18:42 [medline]
PHST- 2023/09/29 18:42 [pubmed]
PHST- 2023/09/29 14:28 [entrez]
AID - 10.1007/s00417-023-06256-1 [pii]
AID - 10.1007/s00417-023-06256-1 [doi]
PST - aheadofprint
SO  - Graefes Arch Clin Exp Ophthalmol. 2023 Sep 29. doi: 10.1007/s00417-023-06256-1.

PMID- 37773197
OWN - NLM
STAT- MEDLINE
DCOM- 20231005
LR  - 20231123
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 13
IP  - 1
DP  - 2023 Sep 29
TI  - A fast and accurate identification model for Rhinolophus bats based on 
      fine-grained information.
PG  - 16375
LID - 10.1038/s41598-023-42577-1 [doi]
LID - 16375
AB  - Bats are a crucial component within ecosystems, providing valuable ecosystem 
      services such as pollination and pest control. In practical conservation efforts, 
      the classification and identification of bats are essential in order to develop 
      effective conservation management programs for bats and their habitats. 
      Traditionally, the identification of bats has been a manual and time-consuming 
      process. With the development of artificial intelligence technology, the accuracy 
      and speed of identification work of such fine-grained images as bats 
      identification can be greatly improved. Bats identification relies on the fine 
      features of their beaks and faces, so mining the fine-grained information in 
      images is crucial to improve the accuracy of bats identification. This paper 
      presents a deep learning-based model designed for the rapid and precise 
      identification of common horseshoe bats (Chiroptera: Rhinolophidae: Rhinolophus) 
      from Southern China. The model was developed by utilizing a comprehensive dataset 
      of 883 high-resolution images of seven distinct Rhinolophus species which were 
      collected during surveys conducted between 2010 and 2022. An improved 
      EfficientNet model with an attention mechanism module is architected to mine the 
      fine-grained appearance of these Rhinolophus. The performance of the model beat 
      other classical models, including SqueezeNet, AlexNet, VGG16_BN, ShuffleNetV2, 
      GoogleNet, ResNet50 and EfficientNet_B0, according to the predicting precision, 
      recall, accuracy, F1-score. Our model achieved the highest identification 
      accuracy of 94.22% and an F1-score of 0.948 with low computational complexity. 
      Heat maps obtained with Grad-CAM show that our model meets the identification 
      criteria of the morphology of Rhinolophus. Our study highlights the potential of 
      artificial intelligence technology for the identification of small mammals, and 
      facilitating fast species identification in the future.
CI  - © 2023. Springer Nature Limited.
FAU - Cao, Zhong
AU  - Cao Z
AD  - School of Electronics and Communication Engineering, Guangzhou University, 
      Guangzhou, 510006, China.
FAU - Li, Chuxian
AU  - Li C
AD  - School of Electronics and Communication Engineering, Guangzhou University, 
      Guangzhou, 510006, China.
FAU - Wang, Kunhui
AU  - Wang K
AD  - School of Electronics and Communication Engineering, Guangzhou University, 
      Guangzhou, 510006, China.
FAU - He, Kai
AU  - He K
AD  - School of Life Sciences, Guangzhou University, Guangzhou, 510006, China.
FAU - Wang, Xiaoyun
AU  - Wang X
AD  - School of Life Sciences, Guangzhou University, Guangzhou, 510006, China. 
      wangxy@gzhu.edu.cn.
FAU - Yu, Wenhua
AU  - Yu W
AD  - School of Life Sciences, Guangzhou University, Guangzhou, 510006, China. 
      wenhua_yu@gzhu.edu.cn.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230929
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Animals
MH  - *Chiroptera
MH  - Ecosystem
MH  - Artificial Intelligence
MH  - China
PMC - PMC10541429
COIS- The authors declare no competing interests.
EDAT- 2023/09/29 18:42
MHDA- 2023/10/05 06:44
CRDT- 2023/09/29 13:13
PHST- 2023/06/24 00:00 [received]
PHST- 2023/09/12 00:00 [accepted]
PHST- 2023/10/05 06:44 [medline]
PHST- 2023/09/29 18:42 [pubmed]
PHST- 2023/09/29 13:13 [entrez]
AID - 10.1038/s41598-023-42577-1 [pii]
AID - 42577 [pii]
AID - 10.1038/s41598-023-42577-1 [doi]
PST - epublish
SO  - Sci Rep. 2023 Sep 29;13(1):16375. doi: 10.1038/s41598-023-42577-1.

PMID- 37772992
OWN - NLM
STAT- Publisher
LR  - 20231010
IS  - 2767-9764 (Electronic)
IS  - 2767-9764 (Linking)
VI  - 3
IP  - 9
DP  - 2023 Sep 18
TI  - Accelerating Cancer Histopathology Workflows with Chemical Imaging and Machine 
      Learning.
PG  - 1875-1887
LID - 10.1158/2767-9764.CRC-23-0226 [doi]
AB  - Histopathology has remained a cornerstone for biomedical tissue assessment for 
      over a century, with a resource-intensive workflow involving biopsy or excision, 
      gross examination, sampling, tissue processing to snap frozen or formalin-fixed 
      paraffin-embedded blocks, sectioning, staining, optical imaging, and microscopic 
      assessment. Emerging chemical imaging approaches, including stimulated Raman 
      scattering (SRS) microscopy, can directly measure inherent molecular composition 
      in tissue (thereby dispensing with the need for tissue processing, sectioning, 
      and using dyes) and can use artificial intelligence (AI) algorithms to provide 
      high-quality images. Here we show the integration of SRS microscopy in a 
      pathology workflow to rapidly record chemical information from minimally 
      processed fresh-frozen prostate tissue. Instead of using thin sections, we record 
      data from intact thick tissues and use optical sectioning to generate images from 
      multiple planes. We use a deep learning–based processing pipeline to generate 
      virtual hematoxylin and eosin images. Next, we extend the computational method to 
      generate archival-quality images in minutes, which are equivalent to those 
      obtained from hours/days-long formalin-fixed, paraffin-embedded processing. We 
      assessed the quality of images from the perspective of enabling pathologists to 
      make decisions, demonstrating that the virtual stained image quality was 
      diagnostically useful and the interpathologist agreement on prostate cancer grade 
      was not impacted. Finally, because this method does not wash away lipids and 
      small molecules, we assessed the utility of lipid chemical composition in 
      determining grade. Together, the combination of chemical imaging and AI provides 
      novel capabilities for rapid assessments in pathology by reducing the complexity 
      and burden of current workflows. SIGNIFICANCE: Archival-quality (formalin-fixed 
      paraffin-embedded), thin-section diagnostic images are obtained from thick-cut, 
      fresh-frozen prostate tissues without dyes or stains to expedite cancer 
      histopathology by combining SRS microscopy and machine learning.
CI  - © 2023 The Authors; Published by the American Association for Cancer Research.
FAU - Falahkheirkhah, Kianoush
AU  - Falahkheirkhah K
AUID- ORCID: 0000-0003-2781-2693
AD  - Beckman Institute for Advanced Science and Technology, University of Illinois 
      Urbana-Champaign, Urbana, Illinois.
AD  - Department of Bioengineering, University of Illinois Urbana-Champaign, Urbana, 
      Illinois.
FAU - Mukherjee, Sudipta S
AU  - Mukherjee SS
AUID- ORCID: 0000-0002-4796-2659
AD  - Beckman Institute for Advanced Science and Technology, University of Illinois 
      Urbana-Champaign, Urbana, Illinois.
FAU - Gupta, Sounak
AU  - Gupta S
AUID- ORCID: 0000-0001-5163-6955
AD  - Laboratory Medicine and Pathology, Mayo Clinic, Rochester, Minnesota.
FAU - Herrera-Hernandez, Loren
AU  - Herrera-Hernandez L
AUID- ORCID: 0000-0001-5106-4889
AD  - Laboratory Medicine and Pathology, Mayo Clinic, Rochester, Minnesota.
FAU - McCarthy, Michael R
AU  - McCarthy MR
AUID- ORCID: 0009-0004-9478-3241
AD  - Laboratory Medicine and Pathology, Mayo Clinic, Rochester, Minnesota.
FAU - Jimenez, Rafael E
AU  - Jimenez RE
AUID- ORCID: 0000-0003-2348-0214
AD  - Laboratory Medicine and Pathology, Mayo Clinic, Rochester, Minnesota.
FAU - Cheville, John C
AU  - Cheville JC
AUID- ORCID: 0000-0002-8202-6268
AD  - Laboratory Medicine and Pathology, Mayo Clinic, Rochester, Minnesota.
FAU - Bhargava, Rohit
AU  - Bhargava R
AUID- ORCID: 0000-0001-7360-994X
AD  - Beckman Institute for Advanced Science and Technology, University of Illinois 
      Urbana-Champaign, Urbana, Illinois.
AD  - Department of Bioengineering, University of Illinois Urbana-Champaign, Urbana, 
      Illinois.
AD  - Department of Chemical and Biomolecular Engineering, University of Illinois 
      Urbana-Champaign, Urbana, Illinois.
AD  - Department of Electrical and Computer Engineering, University of Illinois 
      Urbana-Champaign, Urbana, Illinois.
AD  - Mechanical Science and Engineering, University of Illinois Urbana-Champaign, 
      Urbana, Illinois.
AD  - Cancer Center at Illinois, University of Illinois Urbana-Champaign, Urbana, 
      Illinois.
LA  - eng
GR  - P41 EB031772/EB/NIBIB NIH HHS/United States
GR  - R21 CA263147/CA/NCI NIH HHS/United States
PT  - Journal Article
PL  - United States
TA  - Cancer Res Commun
JT  - Cancer research communications
JID - 9918281580506676
SB  - IM
PMC - PMC10506535
EDAT- 2023/09/29 12:43
MHDA- 2023/09/29 12:43
CRDT- 2023/09/29 10:13
PHST- 2023/05/21 00:00 [received]
PHST- 2023/08/21 00:00 [revised]
PHST- 2023/08/21 00:00 [accepted]
PHST- 2023/09/29 12:43 [medline]
PHST- 2023/09/29 12:43 [pubmed]
PHST- 2023/09/29 10:13 [entrez]
AID - 729078 [pii]
AID - CRC-23-0226 [pii]
AID - 10.1158/2767-9764.CRC-23-0226 [doi]
PST - ppublish
SO  - Cancer Res Commun. 2023 Sep 18;3(9):1875-1887. doi: 
      10.1158/2767-9764.CRC-23-0226.

PMID- 37772983
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231025
IS  - 1537-1719 (Electronic)
IS  - 0737-4038 (Print)
IS  - 0737-4038 (Linking)
VI  - 40
IP  - 10
DP  - 2023 Oct 4
TI  - Tensor Decomposition-based Feature Extraction and Classification to Detect 
      Natural Selection from Genomic Data.
LID - 10.1093/molbev/msad216 [doi]
LID - msad216
AB  - Inferences of adaptive events are important for learning about traits, such as 
      human digestion of lactose after infancy and the rapid spread of viral variants. 
      Early efforts toward identifying footprints of natural selection from genomic 
      data involved development of summary statistic and likelihood methods. However, 
      such techniques are grounded in simple patterns or theoretical models that limit 
      the complexity of settings they can explore. Due to the renaissance in artificial 
      intelligence, machine learning methods have taken center stage in recent efforts 
      to detect natural selection, with strategies such as convolutional neural 
      networks applied to images of haplotypes. Yet, limitations of such techniques 
      include estimation of large numbers of model parameters under nonconvex settings 
      and feature identification without regard to location within an image. An 
      alternative approach is to use tensor decomposition to extract features from 
      multidimensional data although preserving the latent structure of the data, and 
      to feed these features to machine learning models. Here, we adopt this framework 
      and present a novel approach termed T-REx, which extracts features from images of 
      haplotypes across sampled individuals using tensor decomposition, and then makes 
      predictions from these features using classical machine learning methods. As a 
      proof of concept, we explore the performance of T-REx on simulated neutral and 
      selective sweep scenarios and find that it has high power and accuracy to 
      discriminate sweeps from neutrality, robustness to common technical hurdles, and 
      easy visualization of feature importance. Therefore, T-REx is a powerful addition 
      to the toolkit for detecting adaptive processes from genomic data.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of Society 
      for Molecular Biology and Evolution.
FAU - Amin, Md Ruhul
AU  - Amin MR
AD  - Department of Electrical Engineering and Computer Science, Florida Atlantic 
      University, Boca Raton, FL 33431, USA.
FAU - Hasan, Mahmudul
AU  - Hasan M
AD  - Department of Electrical Engineering and Computer Science, Florida Atlantic 
      University, Boca Raton, FL 33431, USA.
FAU - Arnab, Sandipan Paul
AU  - Arnab SP
AUID- ORCID: 0000-0003-0827-5327
AD  - Department of Electrical Engineering and Computer Science, Florida Atlantic 
      University, Boca Raton, FL 33431, USA.
FAU - DeGiorgio, Michael
AU  - DeGiorgio M
AUID- ORCID: 0000-0003-4908-7234
AD  - Department of Electrical Engineering and Computer Science, Florida Atlantic 
      University, Boca Raton, FL 33431, USA.
LA  - eng
GR  - R35 GM128590/GM/NIGMS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - United States
TA  - Mol Biol Evol
JT  - Molecular biology and evolution
JID - 8501455
SB  - IM
UOF - bioRxiv. 2023 Mar 29;:. PMID: 37034767
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Genomics/methods
MH  - Neural Networks, Computer
MH  - Machine Learning
MH  - Selection, Genetic
PMC - PMC10581699
OTO - NOTNLM
OT  - candecomp/parafac
OT  - dimensionality reduction
OT  - positive natural selection
OT  - tensor decomposition
EDAT- 2023/09/29 12:43
MHDA- 2023/10/23 01:18
CRDT- 2023/09/29 10:03
PHST- 2023/03/02 00:00 [received]
PHST- 2023/08/10 00:00 [revised]
PHST- 2023/09/14 00:00 [accepted]
PHST- 2023/10/23 01:18 [medline]
PHST- 2023/09/29 12:43 [pubmed]
PHST- 2023/09/29 10:03 [entrez]
AID - 7286307 [pii]
AID - msad216 [pii]
AID - 10.1093/molbev/msad216 [doi]
PST - ppublish
SO  - Mol Biol Evol. 2023 Oct 4;40(10):msad216. doi: 10.1093/molbev/msad216.
