PMID- 37770336
OWN - NLM
STAT- MEDLINE
DCOM- 20231030
LR  - 20231030
IS  - 2589-7500 (Electronic)
IS  - 2589-7500 (Linking)
VI  - 5
IP  - 11
DP  - 2023 Nov
TI  - Stepping stones and challenges in the use of artificial intelligence in the 
      diagnosis of echinococcosis.
PG  - e750-e751
LID - S2589-7500(23)00183-8 [pii]
LID - 10.1016/S2589-7500(23)00183-8 [doi]
FAU - Manciulli, Tommaso
AU  - Manciulli T
AD  - Department of Clinical and Experimental Medicine, University of Florence, 
      Florence, Italy; WHO Collaborating Center for the Clinical Management of Cystic 
      Echinococcosis, University of Pavia, Pavia, Italy. Electronic address: 
      tommaso.manciulli@unifi.it.
FAU - Brunetti, Enrico
AU  - Brunetti E
AD  - WHO Collaborating Center for the Clinical Management of Cystic Echinococcosis, 
      University of Pavia, Pavia, Italy; Immunology and Infectious Diseases, San Matteo 
      Hospital Foundation, Pavia, Italy; Department of Clinical-Surgical, Diagnostic, 
      and Pediatric Sciences, University of Pavia, Pavia, Italy.
LA  - eng
PT  - Comment
PT  - Journal Article
DEP - 20230926
PL  - England
TA  - Lancet Digit Health
JT  - The Lancet. Digital health
JID - 101751302
SB  - IM
CON - Lancet Digit Health. 2023 Aug;5(8):e503-e514. PMID: 37507196
CON - Lancet Digit Health. 2023 Nov;5(11):e754-e762. PMID: 37770335
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Echinococcosis/diagnosis
COIS- We declare no competing interests. We thank Sam Goblirsch for reviewing the paper 
      for English grammar and style.
EDAT- 2023/09/29 00:42
MHDA- 2023/10/30 06:46
CRDT- 2023/09/28 21:56
PHST- 2023/07/29 00:00 [received]
PHST- 2023/09/13 00:00 [accepted]
PHST- 2023/10/30 06:46 [medline]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/28 21:56 [entrez]
AID - S2589-7500(23)00183-8 [pii]
AID - 10.1016/S2589-7500(23)00183-8 [doi]
PST - ppublish
SO  - Lancet Digit Health. 2023 Nov;5(11):e750-e751. doi: 
      10.1016/S2589-7500(23)00183-8. Epub 2023 Sep 26.

PMID- 37770335
OWN - NLM
STAT- MEDLINE
DCOM- 20231030
LR  - 20231030
IS  - 2589-7500 (Electronic)
IS  - 2589-7500 (Linking)
VI  - 5
IP  - 11
DP  - 2023 Nov
TI  - Detection and subtyping of hepatic echinococcosis from plain CT images with deep 
      learning: a retrospective, multicentre study.
PG  - e754-e762
LID - S2589-7500(23)00136-X [pii]
LID - 10.1016/S2589-7500(23)00136-X [doi]
AB  - BACKGROUND: Hepatic echinococcosis is a severe endemic disease in some 
      underdeveloped rural areas worldwide. Qualified physicians are in short supply in 
      such areas, resulting in low rates of accurate diagnosis of this condition. In 
      this study, we aimed to develop and evaluate an artificial intelligence (AI) 
      system for automated detection and subtyping of hepatic echinococcosis using 
      plain CT images with the goal of providing interpretable assistance to 
      radiologists and clinicians. METHODS: We developed EDAM, an echinococcosis 
      diagnostic AI system, to provide accurate and generalisable CT analysis for 
      distinguishing hepatic echinococcosis from hepatic cysts and normal controls (no 
      liver lesions), as well as subtyping hepatic echinococcosis as alveolar or cystic 
      echinococcosis. EDAM includes a slice-level prediction model for lesion 
      classification and segmentation and a patient-level diagnostic model for patient 
      classification. We collected a plain CT database (n=700: 395 cystic 
      echinococcosis, 122 alveolar echinococcosis, 130 hepatic cysts, and 53 normal 
      controls) for developing EDAM, and two additional independent cohorts (n=156) for 
      external validation of its performance and generalisation ability. We compared 
      the performance of EDAM with 52 experienced radiologists in diagnosing and 
      subtyping hepatic echinococcosis. FINDINGS: EDAM showed reliable performance in 
      patient-level diagnosis on both the internal testing data (overall area under the 
      receiver operating characteristic curve [AUC]: 0·974 [95% CI 0·936-0·994]; 
      accuracy: 0·952 [0·939-0·965] for cystic echinococcosis, 0·981 [0·973-0·989] for 
      alveolar echinococcosis; sensitivity: 0·966 [0·951-0·979] for cystic 
      echinococcosis, 0·944 [0·908-0·970] for alveolar echinococcosis) and the external 
      testing set (overall AUC: 0·953 [95% CI 0·840-0·973]; accuracy: 0·929 
      [0·915-0·947] for cystic echinococcosis, 0·936 [0·919-0·950] for alveolar 
      echinococcosis; sensitivity: 0·913 [0·879-0·944] for cystic echinococcosis, 0·868 
      [0·841-0·897] for alveolar echinococcosis). The sensitivity of EDAM was robust 
      across images from different CT manufacturers. EDAM outperformed most of the 
      enrolled radiologists in detecting both alveolar echinococcosis and cystic 
      echinococcosis. INTERPRETATION: EDAM is a clinically applicable AI system that 
      can provide patient-level diagnoses with interpretable results. The accuracy and 
      generalisation ability of EDAM demonstrates its potential for clinical use, 
      especially in underdeveloped areas. FUNDING: Project of Qinghai Provincial 
      Department of Science and Technology of China, National Natural Science 
      Foundation of China, and Tsinghua-Fuzhou Institute of Data Technology Project. 
      TRANSLATION: For the Chinese translation of the abstract see Supplementary 
      Materials section.
CI  - Copyright © 2023 The Author(s). Published by Elsevier Ltd. This is an Open Access 
      article under the CC BY-NC-ND 4.0 license. Published by Elsevier Ltd.. All rights 
      reserved.
FAU - Wang, Zhan
AU  - Wang Z
AD  - Department of Biomedical Engineering, Tsinghua University, Beijing, China; 
      Department of Hepatopancreatobiliary Surgery, Qinghai University Affiliated 
      Hospital, Xining, China.
FAU - Bian, Haiyang
AU  - Bian H
AD  - Department of Automation, MOE Key Lab of Bioinformatics and Beijing National 
      Research Center for Information Science & Technology (BNRIST), Tsinghua 
      University, Beijing, China.
FAU - Li, Jiaqi
AU  - Li J
AD  - Department of Automation, MOE Key Lab of Bioinformatics and Beijing National 
      Research Center for Information Science & Technology (BNRIST), Tsinghua 
      University, Beijing, China.
FAU - Xu, Jin
AU  - Xu J
AD  - Department of Medicine, Qinghai University, Xining, China.
FAU - Fan, Haining
AU  - Fan H
AD  - Department of Hepatopancreatobiliary Surgery, Qinghai University Affiliated 
      Hospital, Xining, China.
FAU - Wu, Xinze
AU  - Wu X
AD  - Department of Automation, MOE Key Lab of Bioinformatics and Beijing National 
      Research Center for Information Science & Technology (BNRIST), Tsinghua 
      University, Beijing, China.
FAU - Cao, Yuntai
AU  - Cao Y
AD  - Department of Radiology, Qinghai University Affiliated Hospital, Xining, China.
FAU - Guo, Bin
AU  - Guo B
AD  - Department of Otorhinolaryngology, Qinghai University Affiliated Hospital, 
      Xining, China.
FAU - Xu, Xiaolei
AU  - Xu X
AD  - Department of Hepatopancreatobiliary Surgery, Qinghai University Affiliated 
      Hospital, Xining, China.
FAU - Wang, Haijiu
AU  - Wang H
AD  - Department of Hepatopancreatobiliary Surgery, Qinghai University Affiliated 
      Hospital, Xining, China.
FAU - Zhang, Lingqiang
AU  - Zhang L
AD  - Department of Hepatopancreatobiliary Surgery, Qinghai University Affiliated 
      Hospital, Xining, China.
FAU - Zhou, Hu
AU  - Zhou H
AD  - Department of Hepatopancreatobiliary Surgery, Qinghai University Affiliated 
      Hospital, Xining, China.
FAU - Fan, Jianfeng
AU  - Fan J
AD  - Department of Radiology, Zhenping People's Hospital, Nanyang, China.
FAU - Ren, Youyou
AU  - Ren Y
AD  - Department of Radiology, Nanyang Central Hospital, Nanyang, China.
FAU - Geng, Yunping
AU  - Geng Y
AD  - Department of Radiology, Nanyang Central Hospital, Nanyang, China.
FAU - Feng, Xiaobin
AU  - Feng X
AD  - Hepato-pancreato-biliary Center, Beijing Tsinghua Changgung Hospital, Beijing, 
      China.
FAU - Li, Luming
AU  - Li L
AD  - National Engineering Research Center of Neuromodulation, School of Aerospace 
      Engineering, Tsinghua University, Beijing, China.
FAU - Wei, Lei
AU  - Wei L
AD  - Department of Automation, MOE Key Lab of Bioinformatics and Beijing National 
      Research Center for Information Science & Technology (BNRIST), Tsinghua 
      University, Beijing, China.
FAU - Zhang, Xuegong
AU  - Zhang X
AD  - Department of Automation, MOE Key Lab of Bioinformatics and Beijing National 
      Research Center for Information Science & Technology (BNRIST), Tsinghua 
      University, Beijing, China; School of Medicine and School of Life Sciences, 
      Tsinghua University, Beijing, China. Electronic address: zhangxg@tsinghua.edu.cn.
LA  - eng
PT  - Journal Article
PT  - Multicenter Study
PT  - Research Support, Non-U.S. Gov't
DEP - 20230926
PL  - England
TA  - Lancet Digit Health
JT  - The Lancet. Digital health
JID - 101751302
RN  - Alveolar echinococcosis
RN  - Polycystic liver disease
SB  - IM
CIN - Lancet Digit Health. 2023 Nov;5(11):e750-e751. PMID: 37770336
MH  - Humans
MH  - *Echinococcosis, Hepatic/diagnostic imaging
MH  - Retrospective Studies
MH  - Artificial Intelligence
MH  - *Deep Learning
MH  - *Echinococcosis
MH  - Tomography, X-Ray Computed
MH  - *Cysts
COIS- Declaration of interests We declare no competing interests.
EDAT- 2023/09/29 00:42
MHDA- 2023/10/30 06:46
CRDT- 2023/09/28 21:56
PHST- 2022/10/05 00:00 [received]
PHST- 2023/06/26 00:00 [revised]
PHST- 2023/07/11 00:00 [accepted]
PHST- 2023/10/30 06:46 [medline]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/28 21:56 [entrez]
AID - S2589-7500(23)00136-X [pii]
AID - 10.1016/S2589-7500(23)00136-X [doi]
PST - ppublish
SO  - Lancet Digit Health. 2023 Nov;5(11):e754-e762. doi: 
      10.1016/S2589-7500(23)00136-X. Epub 2023 Sep 26.

PMID- 37770329
OWN - NLM
STAT- Publisher
LR  - 20230928
IS  - 2212-4411 (Electronic)
DP  - 2023 Aug 17
TI  - Detection of extracranial and intracranial calcified carotid artery atheromas in 
      cone beam computed tomography using a deep learning convolutional neural network 
      image segmentation approach.
LID - S2212-4403(23)00620-X [pii]
LID - 10.1016/j.oooo.2023.08.009 [doi]
AB  - OBJECTIVE: We leveraged an artificial intelligence deep-learning convolutional 
      neural network (DL CNN) to detect calcified carotid artery atheromas (CCAAs) on 
      cone beam computed tomography (CBCT) images. STUDY DESIGN: We obtained 137 
      full-volume CBCT scans with previously diagnosed CCAAs. The DL model was trained 
      on 170 single axial CBCT slices, 90 with extracranial CCAAs and 80 with 
      intracranial CCAAs. A board-certified oral and maxillofacial radiologist 
      confirmed the presence of each CCAA. Transfer learning through a U-Net-based CNN 
      architecture was utilized. Data allocation was 60% training, 10% validation, and 
      30% testing. We determined the accuracy of the DL model in detecting CCAA by 
      calculating the mean training and validation accuracy and the area under the 
      receiver operating characteristic curve (AUC). We reserved 5 randomly selected 
      unseen full CBCT volumes for final testing. RESULTS: The mean training and 
      validation accuracy of the model in detecting extracranial CCAAs was 92% and 82%, 
      respectively, and the AUC was 0.84 with 1.0 sensitivity and 0.69 specificity. The 
      mean training and validation accuracy in detecting intracranial CCAAs was 61% and 
      70%, respectively, and the AUC was 0.5 with 0.93 sensitivity and 0.08 
      specificity. Testing of full-volume scans yielded an AUC of 0.72 and 0.55 for 
      extracranial and intracranial CCAAs, respectively. CONCLUSION: Our DL model 
      showed excellent discrimination in detecting extracranial CCAAs on axial CBCT 
      images and acceptable discrimination on full-volumes but poor discrimination in 
      detecting intracranial CCAAs, for which further research is required.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Alajaji, Shahd A
AU  - Alajaji SA
AD  - Department of Oncology and Diagnostic Sciences, School of Dentistry, University 
      of Maryland Baltimore, MD, USA; Division of Artificial Intelligence Research, 
      University of Maryland School of Dentistry, Baltimore, MD, USA; Department of 
      Oral Medicine and Diagnostic Sciences, College of Dentistry, King Saud 
      University, Riyadh, Saudi Arabia.
FAU - Amarin, Rula
AU  - Amarin R
AD  - Department of Advanced Oral Sciences and Therapeutics, School of Dentistry, 
      University of Maryland, Baltimore, MD, USA.
FAU - Masri, Radi
AU  - Masri R
AD  - Department of Advanced Oral Sciences and Therapeutics, School of Dentistry, 
      University of Maryland, Baltimore, MD, USA.
FAU - Tavares, Tiffany
AU  - Tavares T
AD  - Department of Comprehensive Dentistry, UT Health San Antonio, School of 
      Dentistry, San Antonio, TX, USA.
FAU - Kumar, Vandana
AU  - Kumar V
AD  - Department of Oncology and Diagnostic Sciences, School of Dentistry, University 
      of Maryland Baltimore, MD, USA.
FAU - Price, Jeffery B
AU  - Price JB
AD  - Department of Oncology and Diagnostic Sciences, School of Dentistry, University 
      of Maryland Baltimore, MD, USA; Division of Artificial Intelligence Research, 
      University of Maryland School of Dentistry, Baltimore, MD, USA.
FAU - Sultan, Ahmed S
AU  - Sultan AS
AD  - Department of Oncology and Diagnostic Sciences, School of Dentistry, University 
      of Maryland Baltimore, MD, USA; Division of Artificial Intelligence Research, 
      University of Maryland School of Dentistry, Baltimore, MD, USA; Marlene and 
      Stewart Greenebaum Comprehensive Cancer Center, University of Maryland, 
      Baltimore, MD, USA. Electronic address: Asultan1@umaryland.edu.
LA  - eng
PT  - Journal Article
DEP - 20230817
PL  - United States
TA  - Oral Surg Oral Med Oral Pathol Oral Radiol
JT  - Oral surgery, oral medicine, oral pathology and oral radiology
JID - 101576782
SB  - IM
COIS- Declaration of interest None.
EDAT- 2023/09/29 00:42
MHDA- 2023/09/29 00:42
CRDT- 2023/09/28 21:55
PHST- 2023/02/24 00:00 [received]
PHST- 2023/07/16 00:00 [revised]
PHST- 2023/08/04 00:00 [accepted]
PHST- 2023/09/29 00:42 [medline]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/28 21:55 [entrez]
AID - S2212-4403(23)00620-X [pii]
AID - 10.1016/j.oooo.2023.08.009 [doi]
PST - aheadofprint
SO  - Oral Surg Oral Med Oral Pathol Oral Radiol. 2023 Aug 17:S2212-4403(23)00620-X. 
      doi: 10.1016/j.oooo.2023.08.009.

PMID- 37770007
OWN - NLM
STAT- Publisher
LR  - 20231020
IS  - 1532-8406 (Electronic)
IS  - 0883-5403 (Linking)
DP  - 2023 Sep 26
TI  - THA-AID: Deep Learning Tool for Total Hip Arthroplasty Automatic Implant 
      Detection With Uncertainty and Outlier Quantification.
LID - S0883-5403(23)00983-X [pii]
LID - 10.1016/j.arth.2023.09.025 [doi]
AB  - BACKGROUND: Revision total hip arthroplasty (THA) requires preoperatively 
      identifying in situ implants, a time-consuming and sometimes unachievable task. 
      Although deep learning (DL) tools have been attempted to automate this process, 
      existing approaches are limited by classifying few femoral and zero acetabular 
      components, only classify on anterior-posterior (AP) radiographs, and do not 
      report prediction uncertainty or flag outlier data. METHODS: This study 
      introduces Total Hip Arhtroplasty Automated Implant Detector (THA-AID), a DL tool 
      trained on 241,419 radiographs that identifies common designs of 20 femoral and 8 
      acetabular components from AP, lateral, or oblique views and reports prediction 
      uncertainty using conformal prediction and outlier detection using a custom 
      framework. We evaluated THA-AID using internal, external, and out-of-domain test 
      sets and compared its performance with human experts. RESULTS: THA-AID achieved 
      internal test set accuracies of 98.9% for both femoral and acetabular components 
      with no significant differences based on radiographic view. The femoral 
      classifier also achieved 97.0% accuracy on the external test set. Adding 
      conformal prediction increased true label prediction by 0.1% for acetabular and 
      0.7 to 0.9% for femoral components. More than 99% of out-of-domain and >89% of 
      in-domain outlier data were correctly identified by THA-AID. CONCLUSIONS: The 
      THA-AID is an automated tool for implant identification from radiographs with 
      exceptional performance on internal and external test sets and no decrement in 
      performance based on radiographic view. Importantly, this is the first study in 
      orthopedics to our knowledge including uncertainty quantification and outlier 
      detection of a DL model.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Rouzrokh, Pouria
AU  - Rouzrokh P
AD  - Department of Radiology, Mayo Clinic, Rochester, Minnesota.
FAU - Mickley, John P
AU  - Mickley JP
AD  - Department of Orthopedic Surgery, Mayo Clinic, Rochester, Minnesota.
FAU - Khosravi, Bardia
AU  - Khosravi B
AD  - Department of Radiology, Mayo Clinic, Rochester, Minnesota.
FAU - Faghani, Shahriar
AU  - Faghani S
AD  - Department of Radiology, Mayo Clinic, Rochester, Minnesota.
FAU - Moassefi, Mana
AU  - Moassefi M
AD  - Department of Radiology, Mayo Clinic, Rochester, Minnesota.
FAU - Schulz, William R
AU  - Schulz WR
AD  - Department of Orthopedic Surgery, Mayo Clinic, Rochester, Minnesota.
FAU - Erickson, Bradley J
AU  - Erickson BJ
AD  - Department of Radiology, Mayo Clinic, Rochester, Minnesota.
FAU - Taunton, Michael J
AU  - Taunton MJ
AD  - Department of Orthopedic Surgery, Mayo Clinic, Rochester, Minnesota.
FAU - Wyles, Cody C
AU  - Wyles CC
AD  - Department of Orthopedic Surgery, Mayo Clinic, Rochester, Minnesota.
LA  - eng
PT  - Journal Article
DEP - 20230926
PL  - United States
TA  - J Arthroplasty
JT  - The Journal of arthroplasty
JID - 8703515
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - conformal prediction
OT  - deep learning
OT  - implant identification
OT  - total hip arthroplasty
OT  - uncertainty quantification
EDAT- 2023/09/29 00:42
MHDA- 2023/09/29 00:42
CRDT- 2023/09/28 19:35
PHST- 2023/07/03 00:00 [received]
PHST- 2023/09/13 00:00 [revised]
PHST- 2023/09/16 00:00 [accepted]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/29 00:42 [medline]
PHST- 2023/09/28 19:35 [entrez]
AID - S0883-5403(23)00983-X [pii]
AID - 10.1016/j.arth.2023.09.025 [doi]
PST - aheadofprint
SO  - J Arthroplasty. 2023 Sep 26:S0883-5403(23)00983-X. doi: 
      10.1016/j.arth.2023.09.025.

PMID- 37769940
OWN - NLM
STAT- MEDLINE
DCOM- 20240102
LR  - 20240102
IS  - 1535-7732 (Electronic)
IS  - 1051-0443 (Linking)
VI  - 35
IP  - 1
DP  - 2024 Jan
TI  - An Interventional Radiologist's Primer of Critical Appraisal of Artificial 
      Intelligence Research.
PG  - 7-14
LID - S1051-0443(23)00696-6 [pii]
LID - 10.1016/j.jvir.2023.09.020 [doi]
AB  - Recent advances in artificial intelligence (AI) are expected to cause a 
      significant paradigm shift in all digital data-driven aspects of information 
      gain, processing, and decision making in both clinical healthcare and medical 
      research. The field of interventional radiology (IR) will be enmeshed in this 
      innovation, yet the collective IR expertise in the field of AI remains 
      rudimentary because of lack of training. This primer provides the clinical 
      interventional radiologist with a simple guide for critically appraising AI 
      research and products by identifying 12 fundamental items that should be 
      considered: (a) need for AI technology to address the clinical problem, (b) type 
      of applied Al algorithm, (c) data quality and degree of annotation, (d) reporting 
      of accuracy, (e) applicability of standardized reporting, (f) reproducibility of 
      methodology and data transparency, (g) algorithm validation, (h) 
      interpretability, (i) concrete impact on IR, (j) pathway toward translation to 
      clinical practice, (k) clinical benefit and cost-effectiveness, and (l) 
      regulatory framework.
CI  - Copyright © 2023 SIR. Published by Elsevier Inc. All rights reserved.
FAU - Gaddum, Olivia
AU  - Gaddum O
AD  - Division of Interventional Radiology, Department of Radiology and Biomedical 
      Imaging, Yale University School of Medicine, New Haven, Connecticut.
FAU - Chapiro, Julius
AU  - Chapiro J
AD  - Division of Interventional Radiology, Department of Radiology and Biomedical 
      Imaging, Yale University School of Medicine, New Haven, Connecticut. Electronic 
      address: julius.chapiro@yale.edu.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230926
PL  - United States
TA  - J Vasc Interv Radiol
JT  - Journal of vascular and interventional radiology : JVIR
JID - 9203369
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Algorithms
MH  - *Biomedical Research
MH  - Radiologists
EDAT- 2023/09/29 00:41
MHDA- 2024/01/02 11:45
CRDT- 2023/09/28 19:33
PHST- 2023/04/25 00:00 [received]
PHST- 2023/07/17 00:00 [revised]
PHST- 2023/09/18 00:00 [accepted]
PHST- 2024/01/02 11:45 [medline]
PHST- 2023/09/29 00:41 [pubmed]
PHST- 2023/09/28 19:33 [entrez]
AID - S1051-0443(23)00696-6 [pii]
AID - 10.1016/j.jvir.2023.09.020 [doi]
PST - ppublish
SO  - J Vasc Interv Radiol. 2024 Jan;35(1):7-14. doi: 10.1016/j.jvir.2023.09.020. Epub 
      2023 Sep 26.

PMID- 37769929
OWN - NLM
STAT- MEDLINE
DCOM- 20231106
LR  - 20231106
IS  - 1873-7528 (Electronic)
IS  - 0149-7634 (Linking)
VI  - 154
DP  - 2023 Nov
TI  - Are domesticated animals dumber than their wild relatives? A comprehensive review 
      on the domestication effects on animal cognitive performance.
PG  - 105407
LID - S0149-7634(23)00376-7 [pii]
LID - 10.1016/j.neubiorev.2023.105407 [doi]
AB  - Animal domestication leads to diverse behavioral, physiological, and 
      neurocognitive changes in domesticated species compared to their wild relatives. 
      However, the widely held belief that domesticated species are inherently less 
      "intelligent" (i.e., have lower cognitive performance) than their wild 
      counterparts requires further investigation. To investigate potential cognitive 
      disparities, we undertook a thorough review of 88 studies comparing the cognitive 
      performance of domesticated and wild animals. Approximately 30% of these studies 
      showed superior cognitive abilities in wild animals, while another 30% 
      highlighted superior cognitive abilities in domesticated animals. The remaining 
      40% of studies found similar cognitive performance between the two groups. 
      Therefore, the question regarding the presumed intelligence of wild animals and 
      the diminished cognitive ability of domesticated animals remains unresolved. We 
      discuss important factors/limitations for interpreting past and future research, 
      including environmental influences, diverse objectives of domestication (such as 
      breed development), developmental windows, and methodological issues impacting 
      cognitive comparisons. Rather than perceiving these limitations as constraints, 
      future researchers should embrace them as opportunities to expand our 
      understanding of the complex relationship between domestication and animal 
      cognition.
CI  - Copyright © 2023 The Authors. Published by Elsevier Ltd.. All rights reserved.
FAU - Ferreira, Vitor Hugo Bessa
AU  - Ferreira VHB
AD  - IFM Biology, AVIAN Behavioural Genomics and Physiology group, Linköping 
      University, 581 83 Linköping, Sweden; INRAE, CNRS, IFCE, Université de Tours, 
      Centre Val de Loire UMR Physiologie de la Reproduction et des Comportements, 
      37380 Nouzilly, France. Electronic address: vitor.ferreira@inrae.fr.
FAU - Lansade, Léa
AU  - Lansade L
AD  - INRAE, CNRS, IFCE, Université de Tours, Centre Val de Loire UMR Physiologie de la 
      Reproduction et des Comportements, 37380 Nouzilly, France.
FAU - Calandreau, Ludovic
AU  - Calandreau L
AD  - INRAE, CNRS, IFCE, Université de Tours, Centre Val de Loire UMR Physiologie de la 
      Reproduction et des Comportements, 37380 Nouzilly, France.
FAU - Cunha, Felipe
AU  - Cunha F
AD  - IFM Biology, AVIAN Behavioural Genomics and Physiology group, Linköping 
      University, 581 83 Linköping, Sweden.
FAU - Jensen, Per
AU  - Jensen P
AD  - IFM Biology, AVIAN Behavioural Genomics and Physiology group, Linköping 
      University, 581 83 Linköping, Sweden. Electronic address: per.jensen@liu.se.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230926
PL  - United States
TA  - Neurosci Biobehav Rev
JT  - Neuroscience and biobehavioral reviews
JID - 7806090
SB  - IM
MH  - Animals
MH  - *Domestication
MH  - *Animals, Domestic
MH  - Cognition
OTO - NOTNLM
OT  - Animal cognition
OT  - Animal domestication
OT  - Cognitive performance
OT  - Comparative studies
OT  - Domesticated animals
OT  - Intelligence
OT  - Neurocognitive changes
OT  - Wild animals
COIS- Declaration of interest None
EDAT- 2023/09/29 00:42
MHDA- 2023/11/06 06:42
CRDT- 2023/09/28 19:33
PHST- 2023/06/01 00:00 [received]
PHST- 2023/09/21 00:00 [revised]
PHST- 2023/09/22 00:00 [accepted]
PHST- 2023/11/06 06:42 [medline]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/28 19:33 [entrez]
AID - S0149-7634(23)00376-7 [pii]
AID - 10.1016/j.neubiorev.2023.105407 [doi]
PST - ppublish
SO  - Neurosci Biobehav Rev. 2023 Nov;154:105407. doi: 10.1016/j.neubiorev.2023.105407. 
      Epub 2023 Sep 26.

PMID- 37769849
OWN - NLM
STAT- Publisher
LR  - 20231025
IS  - 1569-8041 (Electronic)
IS  - 0923-7534 (Linking)
DP  - 2023 Sep 26
TI  - Challenges of artificial intelligence in precision oncology: public-private 
      partnerships including national health agencies as an asset to make it happen.
LID - S0923-7534(23)03944-3 [pii]
LID - 10.1016/j.annonc.2023.09.3106 [doi]
FAU - Luu, V P
AU  - Luu VP
AD  - Epidemiology and innovation Unit, Artificial Intelligence and Cancers 
      Association, Paris, France. Electronic address: vinh-phuc.luu@filiere-ia.fr.
FAU - Fiorini, M
AU  - Fiorini M
AD  - Artificial Intelligence and Cancers Association, Paris, France.
FAU - Combes, S
AU  - Combes S
AD  - Health Data Hub, Paris, France.
FAU - Quemeneur, E
AU  - Quemeneur E
AD  - France Biotech, Paris, France; Transgene S.A., Illkirch-Graffenstaden, France.
FAU - Bonneville, M
AU  - Bonneville M
AD  - Alliance pour la Recherche et l'Innovation des Industries de Santé, Paris, 
      France; Institut Mérieux, Lyon, France.
FAU - Bousquet, P J
AU  - Bousquet PJ
AD  - Health Survey, Data-Science, Assessment Division, Institut National du Cancer, 
      Boulogne Billancourt, France; Aix Marseille University, INSERM, IRD, Economics 
      and Social Sciences Applied to Health & Analysis of Medical Information 
      (SESSTIM), Marseille, France.
LA  - eng
PT  - Editorial
DEP - 20230926
PL  - England
TA  - Ann Oncol
JT  - Annals of oncology : official journal of the European Society for Medical 
      Oncology
JID - 9007735
SB  - IM
COIS- Disclosure VPL is employed by Artificial Intelligence and Cancers Association. MF 
      is employed by Artificial Intelligence and Cancers Association. SC is employed by 
      the French Health Data Hub, which is an independent national health agency and a 
      member of Artificial Intelligence and Cancers Association. EQ is employed by 
      France Biotech, which is a member of Artificial Intelligence and Cancers 
      Association. MB is employed by the Health Industry Alliance for Research and 
      Innovation (ARIIS), which is a member of Artificial Intelligence and Cancers 
      Association. PJB is employed by the French National Institute of Cancer, which is 
      an independent national health agency and a member of Artificial Intelligence and 
      Cancers Association.
EDAT- 2023/09/29 00:42
MHDA- 2023/09/29 00:42
CRDT- 2023/09/28 19:31
PHST- 2023/04/18 00:00 [received]
PHST- 2023/07/13 00:00 [revised]
PHST- 2023/09/17 00:00 [accepted]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/29 00:42 [medline]
PHST- 2023/09/28 19:31 [entrez]
AID - S0923-7534(23)03944-3 [pii]
AID - 10.1016/j.annonc.2023.09.3106 [doi]
PST - aheadofprint
SO  - Ann Oncol. 2023 Sep 26:S0923-7534(23)03944-3. doi: 10.1016/j.annonc.2023.09.3106.

PMID- 37769829
OWN - NLM
STAT- MEDLINE
DCOM- 20231114
LR  - 20231114
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Linking)
VI  - 147
DP  - 2023 Nov
TI  - Data-driven overdiagnosis definitions: A scoping review.
PG  - 104506
LID - S1532-0464(23)00227-7 [pii]
LID - 10.1016/j.jbi.2023.104506 [doi]
AB  - INTRODUCTION: Adequate methods to promptly translate digital health innovations 
      for improved patient care are essential. Advances in Artificial Intelligence (AI) 
      and Machine Learning (ML) have been sources of digital innovation and hold the 
      promise to revolutionize the way we treat, manage and diagnose patients. 
      Understanding the benefits but also the potential adverse effects of digital 
      health innovations, particularly when these are made available or applied on 
      healthier segments of the population is essential. One of such adverse effects is 
      overdiagnosis. OBJECTIVE: to comprehensively analyze quantification strategies 
      and data-driven definitions for overdiagnosis reported in the literature. 
      METHODS: we conducted a scoping systematic review of manuscripts describing 
      quantitative methods to estimate the proportion of overdiagnosed patients. 
      RESULTS: we identified 46 studies that met our inclusion criteria. They covered a 
      variety of clinical conditions, primarily breast and prostate cancer. Methods to 
      quantify overdiagnosis included both prospective and retrospective methods 
      including randomized clinical trials, and simulations. CONCLUSION: a variety of 
      methods to quantify overdiagnosis have been published, producing widely diverging 
      results. A standard method to quantify overdiagnosis is needed to allow its 
      mitigation during the rapidly increasing development of new digital diagnostic 
      tools.
CI  - Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Senevirathna, Prabodi
AU  - Senevirathna P
AD  - School of Computing and Information Systems, The University of Melbourne, 
      Melbourne, 3053, Victoria, Australia.
FAU - Pires, Douglas E V
AU  - Pires DEV
AD  - School of Computing and Information Systems, The University of Melbourne, 
      Melbourne, 3053, Victoria, Australia; Centre for Digital Transformation of 
      Health, The University of Melbourne, Melbourne, 3053, Victoria, Australia. 
      Electronic address: douglas.pires@unimelb.edu.au.
FAU - Capurro, Daniel
AU  - Capurro D
AD  - School of Computing and Information Systems, The University of Melbourne, 
      Melbourne, 3053, Victoria, Australia; Centre for Digital Transformation of 
      Health, The University of Melbourne, Melbourne, 3053, Victoria, Australia; 
      Department of General Medicine, Royal Melbourne Hospital, Melbourne, 3053, 
      Victoria, Australia. Electronic address: dcapurro@unimelb.edu.au.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Review
PT  - Systematic Review
DEP - 20230927
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Male
MH  - Humans
MH  - Retrospective Studies
MH  - *Artificial Intelligence
MH  - Overdiagnosis
MH  - Prospective Studies
MH  - *Prostatic Neoplasms/diagnosis
OTO - NOTNLM
OT  - Clinical trajectories
OT  - Digital overdiagnosis
OT  - Digital screening
OT  - Overdiagnosis
COIS- Declaration of competing interest The authors declare the following financial 
      interests/personal relationships which may be considered as potential competing 
      interests: Daniel Capurro reports a relationship with Medical Research Future 
      Fund that includes: funding grants. Corresponding author is a member of the 
      journal’s Editorial Board
EDAT- 2023/09/29 00:42
MHDA- 2023/11/14 06:42
CRDT- 2023/09/28 19:30
PHST- 2023/01/05 00:00 [received]
PHST- 2023/09/17 00:00 [revised]
PHST- 2023/09/22 00:00 [accepted]
PHST- 2023/11/14 06:42 [medline]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/28 19:30 [entrez]
AID - S1532-0464(23)00227-7 [pii]
AID - 10.1016/j.jbi.2023.104506 [doi]
PST - ppublish
SO  - J Biomed Inform. 2023 Nov;147:104506. doi: 10.1016/j.jbi.2023.104506. Epub 2023 
      Sep 27.

PMID- 37769746
OWN - NLM
STAT- Publisher
LR  - 20231022
IS  - 1095-953X (Electronic)
IS  - 0969-9961 (Linking)
VI  - 187
DP  - 2023 Oct 15
TI  - Deep learning combining FDG-PET and neurocognitive data accurately predicts MCI 
      conversion to Alzheimer's dementia 3-year post MCI diagnosis.
PG  - 106310
LID - S0969-9961(23)00326-1 [pii]
LID - 10.1016/j.nbd.2023.106310 [doi]
AB  - INTRODUCTION: This study reports a novel deep learning approach to predict mild 
      cognitive impairment (MCI) conversion to Alzheimer's dementia (AD) within three 
      years using whole-brain fluorodeoxyglucose (FDG) positron emission tomography 
      (PET) and cognitive scores (CS). METHODS: This analysis consisted of 150 normal 
      controls (CN), 257 MCI, and 205  AD subjects from ADNI. FDG-PET and CS were 
      obtained at MCI diagnosis to predict AD conversion within three years of MCI 
      diagnosis using convolutional neural networks. RESULTS: Neurocognitive scores 
      predicted better than FDG-PET per se, but the best model was a combination of 
      FDG-PET, age, and neurocognitive data, yielding an AUC of 0.785 ± 0.096 and a 
      balanced accuracy of 0.733 ± 0.098. Saliency maps highlighted putamen, thalamus, 
      inferior frontal gyrus, parietal operculum, precuneus cortices, calcarine 
      cortices, temporal gyrus, and planum temporale to be important for prediction. 
      DISCUSSION: Deep learning accurately predicts MCI conversion to AD and provides 
      neural correlates of brain regions associated with AD conversion.
CI  - Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Cao, Eric
AU  - Cao E
AD  - Department of Radiology, Albert Einstein College of Medicine and Montefiore 
      Medical Center, Bronx, NY 10467, United States.
FAU - Ma, Da
AU  - Ma D
AD  - Department of Internal Medicine Section of Gerontology and Geriatric Medicine, 
      Wake Forest, University School of Medicine, Winston-Salam, NC 27109, United 
      States.
FAU - Nayak, Siddharth
AU  - Nayak S
AD  - Department of Radiology, Weill Cornell Medicine, New York, 10065, United States.
FAU - Duong, Tim Q
AU  - Duong TQ
AD  - Department of Radiology, Albert Einstein College of Medicine and Montefiore 
      Medical Center, Bronx, NY 10467, United States. Electronic address: 
      Tim.duong@einsteinmed.edu.
LA  - eng
PT  - Journal Article
DEP - 20230926
PL  - United States
TA  - Neurobiol Dis
JT  - Neurobiology of disease
JID - 9500169
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Dementia
OT  - MRI
OT  - Machine learning
OT  - Mild cognitive impairment
OT  - Positron emission tomography
COIS- Declaration of Competing Interest Authors declare no conflict of interest.
EDAT- 2023/09/29 00:42
MHDA- 2023/09/29 00:42
CRDT- 2023/09/28 19:28
PHST- 2023/03/28 00:00 [received]
PHST- 2023/09/20 00:00 [revised]
PHST- 2023/09/25 00:00 [accepted]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/29 00:42 [medline]
PHST- 2023/09/28 19:28 [entrez]
AID - S0969-9961(23)00326-1 [pii]
AID - 10.1016/j.nbd.2023.106310 [doi]
PST - ppublish
SO  - Neurobiol Dis. 2023 Oct 15;187:106310. doi: 10.1016/j.nbd.2023.106310. Epub 2023 
      Sep 26.

PMID- 37769656
OWN - NLM
STAT- MEDLINE
DCOM- 20231026
LR  - 20231113
IS  - 2666-3791 (Electronic)
IS  - 2666-3791 (Linking)
VI  - 4
IP  - 10
DP  - 2023 Oct 17
TI  - AI-clinician collaboration via disagreement prediction: A decision pipeline and 
      retrospective analysis of real-world radiologist-AI interactions.
PG  - 101207
LID - S2666-3791(23)00374-9 [pii]
LID - 10.1016/j.xcrm.2023.101207 [doi]
LID - 101207
AB  - Clinical decision support tools can improve diagnostic performance or reduce 
      variability, but they are also subject to post-deployment underperformance. 
      Although using AI in an assistive setting offsets many concerns with autonomous 
      AI in medicine, systems that present all predictions equivalently fail to protect 
      against key AI safety concerns. We design a decision pipeline that supports the 
      diagnostic model with an ecosystem of models, integrating disagreement 
      prediction, clinical significance categorization, and prediction quality modeling 
      to guide prediction presentation. We characterize disagreement using data from a 
      deployed chest X-ray interpretation aid and compare clinician burden in this 
      proposed pipeline to the diagnostic model in isolation. The average disagreement 
      rate is 6.5%, and the expected burden reduction is 4.8%, even if 5% of 
      disagreements on urgent findings receive a second read. We conclude that, in our 
      production setting, we can adequately balance risk mitigation with clinician 
      burden if disagreement false positives are reduced.
CI  - Copyright © 2023 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Sanchez, Morgan
AU  - Sanchez M
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA 02115, 
      USA. Electronic address: morgansanchez@g.harvard.edu.
FAU - Alford, Kyle
AU  - Alford K
AD  - Department of Computer Science, Columbia University, New York, NY 10027, USA.
FAU - Krishna, Viswesh
AU  - Krishna V
AD  - Department of Computer Science, Stanford University, Stanford, CA 94301, USA.
FAU - Huynh, Thanh M
AU  - Huynh TM
AD  - VinBrain JSC, Hanoi 11622, Vietnam.
FAU - Nguyen, Chanh D T
AU  - Nguyen CDT
AD  - VinBrain JSC, Hanoi 11622, Vietnam; VinUniversity, Hanoi 12450, Vietnam.
FAU - Lungren, Matthew P
AU  - Lungren MP
AD  - Microsoft Corporation, Redmond, WA 98052, USA; University of California San 
      Francisco, San Francisco, CA 94143, USA; Stanford University, Stanford, CA 94301, 
      USA.
FAU - Truong, Steven Q H
AU  - Truong SQH
AD  - VinBrain JSC, Hanoi 11622, Vietnam; VinUniversity, Hanoi 12450, Vietnam.
FAU - Rajpurkar, Pranav
AU  - Rajpurkar P
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA 02115, 
      USA.
LA  - eng
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20230927
PL  - United States
TA  - Cell Rep Med
JT  - Cell reports. Medicine
JID - 101766894
SB  - IM
MH  - Humans
MH  - Clinical Relevance
MH  - Medicine
MH  - *Radiologists
MH  - Retrospective Studies
MH  - *Artificial Intelligence
PMC - PMC10591030
OTO - NOTNLM
OT  - AI safety
OT  - artificial intelligence
OT  - clinical decision support
OT  - clinician workload estimation
OT  - computer-aided diagnosis
OT  - disagreement prediction
OT  - human-AI collaboration
OT  - machine learning
OT  - radiology
COIS- Declaration of interests M.P.L. is a full-time employee at Microsoft Corporation, 
      and T.M.H., C.D.T.N., and S.Q.H.T. are employees at VinBrain.
EDAT- 2023/09/29 00:42
MHDA- 2023/10/23 01:18
CRDT- 2023/09/28 19:26
PHST- 2022/08/24 00:00 [received]
PHST- 2023/04/18 00:00 [revised]
PHST- 2023/09/03 00:00 [accepted]
PHST- 2023/10/23 01:18 [medline]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/28 19:26 [entrez]
AID - S2666-3791(23)00374-9 [pii]
AID - 101207 [pii]
AID - 10.1016/j.xcrm.2023.101207 [doi]
PST - ppublish
SO  - Cell Rep Med. 2023 Oct 17;4(10):101207. doi: 10.1016/j.xcrm.2023.101207. Epub 
      2023 Sep 27.
